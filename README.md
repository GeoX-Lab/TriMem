# TriMem
<img width="942" height="572" alt="Screenshot 2025-10-22 at 10 09 55" src="https://github.com/user-attachments/assets/faa47566-f43e-454f-990a-a6403eed7c30" />

TriMem formulates the continual learning of vision-language models (VLMs) as the process of establishing new task-specific alignments grounded on pre-existing vision-language correspondence. 

This project is developed based on the ZSCL [code](https://github.com/Thunderbeee/ZSCL). A subset of the core implementation has been released, while the full codebase is still being actively updated and will be released soon.

